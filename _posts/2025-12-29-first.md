---
layout: distill
title: an Introductory post
# description: an example of a distill-style blog post and main elements
tags: distill formatting
giscus_comments: true
date: 2025-12-29
featured: true

authors:
  - name: Ryan Singh

bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
# toc:
#   - name: Equations
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## About me

I am currently a final year PhD student in Christopher Buckley's Lab at the University of Sussex. 

The main focus of the lab can be roughly split into two categories:
* Understanding a specific class of 'biologically-plausible' learning algorithms, namely predictive coding networks. With the eventual aim of providing groundwork for  (a) Neuromorphic AI and (b) understanding biological intelligence. 
* A broader set of cognitive questions thinking within an Active Inference framework. <d-footnote> read Bayesian Inference and active learning </d-footnote>.     


---
## Physical Learning Systems

For me specifically, our current theory of physical learning systems is severely underdeveloped. What do I mean a physical learning system? At the coarsest level a physical learning system:
> An automata which improves it's predictions over time and under which not all transformations are possible.

This seems like a natural starting point for understanding any kind of intelligence  embodied <d-footnote>all intelligence satisfies this claim</d-footnote> in the real world. So why is it underdeveloped? I would argue this is due to a variety of factors. Firstly the focuses of traditional theory

* The blindspot of Information Theory. *Information theory is incredibly useful at allowing us to abstract away physical details of the system, however it can only supply lower bounds away from a large-sytem limit and assigns no cost to computation*.
* Statistics and Control Theory are dominated by performance gaurantees rather than tradeoffs. *In particular traditional statistical theory does not consider computational costs at all.* <d-footnote> On the one hand this has made the cross-talk between machine learning and theory incredibly challenging </d-footnote>
<!-- * Computational Complexity classes. *Based on a universal model of computation*. -->

Secondly the success of Deep Learning has skewed modern research,

* Exploiting scaling laws. *The discovery of data- compute scaling laws and the availability of big data and compute have been exploited at the expense of ever rising energy cost*. <d-footnote>The extreme pessimist would argue that since the invention of backprop there have been no fundamental breakthroughs in Deep Learning and it's success can mostly be attributed to cheaper compute and larger data.</d-footnote>
* Desire for universal learners. *While the human brain clearly has dedicated circuitry for different types of signal and computation, in machine learning (at the cost of resource efficiency) the universal solution is preferred. Designing inductive biases is seen as an anathema c.f. reward is enough*

Put simply, the most developed frameworks we have are designed to ignore physical implementation (as long as it can be put on a universal turing machine).

Why is it important?
* Neuromorphic advantage. *If we don't want to treat neuromorphic devices as turing machines which simply simulate the ideal learner we need to understand problem dependent design choices.* 
* Mechanistic interpretability. *There is currently a severe lack of understanding of the solutions that a neural network finds. Attempts to decode activity almost always use*


## A path forward?
What would a theory of physical learning systems look like?

---

One of the first identifiable developments in what we now call AI was the Hopfield Network. The Hopfield Network was directly answering the question of whether a physical system (it's in the name of the paper!<d-footnote>Neural networks and physical systems with emergent collective computational abilities.</d-footnote>) could learn.    



---
## How did I get here?

When I started my PhD, I was intrigued that Pyschologists categorise memories into Episodic, Semantic, Procedural etc. While as far as I am aware there is no account for this in the theories of learning. Naturally, I thought incoporating these differences as priors (or inductive biases) would be crucial for desinging better learning algorithms. 

However, influenced by the work linking the attention mechanism to Hopfield Networks, my first project was to try and understand the attention mechanism and whether or not there was a link to attention as postulated in predictive coding. Long story short, they are potentially connected if the generative model of agent used a discrete prior over adjacent nodes rather than a continuous prior. This left me wondering if there was some fundamental reason for these discrete priors. Was the switching really a reflection of some property of the world? Perhaps the nature of language data, however vision transformers were already succesful. 

Naturally we began to think of the discreteness as a type of coarse-graining, or intentional forgetting about certain parts of the input. Which led to Poppy and I trying to develop a simple control algorithm, which performed long range planning in the discrete domain, while performing low-level continuous control actions at an approximate level. In particular we wanted to exploit the tractability of evaluating information theoretic optimal exploration terms in the smaller discrete representation.

As an aside, I became curious about certain claims in the Active Inference literature about intrinsic motivation and optimal exploration - which I now understand to be misguided. This led to a fundamental understanding that any non-trivial exploration-exploitation problem is computationally intractable, only approximate solutions are allowed. Further I came to understand that the bayesian solutions are precisely ones that don't forget *any* relevant information from the world.

On the other hand working with Francesco, we had been looking at the theory of predictive coding in linear networks. In such networks it was possible to see explicitly the advantage of iterative inference, since they use more than just the immediate gradient of loss landscape. However we were left wondering whether the time spent performing inference came at exactly the same (or greater) cost as performing multiple gradient steps (I suspect it does). I also started to wonder about whether there are fundamental bounds to different optimisers - a second-optimiser costs more computationally, but allows quicker inference.

Driven by questions about what advantage could be gained by forgetting certain aspects of the world, I began working with Miguel who had been trying to deconstruct Yann Le Cunn's claims about reconstruction. Ultimately we explored a bit of theory which showed that when a JEPA type architecture as enough capacity -- it will converge to the same representation (information theoretically) as an explicit model. With the main of advantage of JEPA as avoiding backpropagating through the explicit model.

---

## Citations

Citations are then used in the article body with the `<d-cite>` tag.
The key attribute is a reference to the id provided in the bibliography.
The key attribute can take multiple ids, separated by commas.

The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover).
If you have an appendix, a bibliography is automatically created and populated in it.

Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover.
However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.

---

## Footnotes

Just wrap the text you would like to show up in a footnote in a `<d-footnote>` tag.
The number of the footnote will be automatically generated.

<d-footnote>This will become a hoverable footnote.</d-footnote>
.